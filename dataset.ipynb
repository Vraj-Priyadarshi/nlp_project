{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FAQ Dataset Preprocessing Pipeline\n",
    "# Input:  dataset/single_qna.csv  (raw Amazon product Q&A)\n",
    "# Output: dataset/faq_data.csv    (clean question + answer pairs)\n",
    "# ============================================================\n",
    "\n",
    "%pip install beautifulsoup4 --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load raw data\n",
    "raw_df = pd.read_csv(\"dataset/single_qna.csv\")\n",
    "print(f\"Raw dataset shape: {raw_df.shape}\")\n",
    "print(f\"\\nColumns: {raw_df.columns.tolist()}\")\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ac2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Keep only relevant columns & initial inspection\n",
    "# ============================================================\n",
    "\n",
    "df = raw_df[['Question', 'Answer', 'Category']].copy()\n",
    "print(f\"Shape after selecting columns: {df.shape}\")\n",
    "print(f\"\\nNull values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"\\nCategories: {df['Category'].nunique()}\")\n",
    "print(f\"\\nSample categories: {df['Category'].value_counts().head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Drop nulls and duplicates\n",
    "# ============================================================\n",
    "\n",
    "df = df.dropna(subset=['Question', 'Answer'])\n",
    "print(f\"After dropping nulls: {df.shape}\")\n",
    "\n",
    "df = df.drop_duplicates(subset=['Question', 'Answer'])\n",
    "print(f\"After dropping duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa91765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Text cleaning function\n",
    "# ============================================================\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean a single text string for FAQ use.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # Replace multiple whitespace/newlines with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the cleaner\n",
    "sample = raw_df['Answer'].iloc[6]\n",
    "print(\"BEFORE:\", sample[:200])\n",
    "print(\"\\nAFTER:\", clean_text(sample)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: Apply cleaning to Question and Answer columns\n",
    "# ============================================================\n",
    "\n",
    "df['Question'] = df['Question'].apply(clean_text)\n",
    "df['Answer'] = df['Answer'].apply(clean_text)\n",
    "\n",
    "print(\"Cleaning complete!\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ef7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 5: Filter out junk / too-short answers\n",
    "# ============================================================\n",
    "\n",
    "# Remove rows where answer is just \"?\" or empty-ish\n",
    "df = df[df['Answer'].str.strip() != '?']\n",
    "df = df[df['Answer'].str.strip() != '']\n",
    "df = df[df['Question'].str.strip() != '']\n",
    "\n",
    "# Remove very short answers (< 10 chars) — likely useless\n",
    "df = df[df['Answer'].str.len() >= 10]\n",
    "\n",
    "# Remove very short questions (< 10 chars)\n",
    "df = df[df['Question'].str.len() >= 10]\n",
    "\n",
    "print(f\"After filtering junk: {df.shape}\")\n",
    "print(f\"\\nSample questions:\")\n",
    "for q in df['Question'].head(5).tolist():\n",
    "    print(f\"  - {q[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 6: Remove duplicate questions (keep best answer — longest)\n",
    "# ============================================================\n",
    "\n",
    "# For FAQ, we want unique questions with the best answer\n",
    "# Sort by answer length (descending) so the longest answer is kept\n",
    "df['answer_len'] = df['Answer'].str.len()\n",
    "df = df.sort_values('answer_len', ascending=False)\n",
    "\n",
    "# Drop duplicate questions, keeping the first (longest answer)\n",
    "df = df.drop_duplicates(subset=['Question'], keep='first')\n",
    "df = df.drop(columns=['answer_len'])\n",
    "\n",
    "print(f\"After dedup by question: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b356500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 7: Truncate very long answers to avoid SBERT token limits\n",
    "# ============================================================\n",
    "\n",
    "MAX_ANSWER_LEN = 512  # characters — keeps it manageable for the model\n",
    "\n",
    "df['Answer'] = df['Answer'].str[:MAX_ANSWER_LEN]\n",
    "\n",
    "print(f\"Answer length stats after truncation:\")\n",
    "print(df['Answer'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b10c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 8: Sample to a manageable size (optional — for faster indexing)\n",
    "# ============================================================\n",
    "# The full dataset is ~1M+ rows. \n",
    "# For a production FAQ demo, 50K-100K is plenty.\n",
    "# Adjust SAMPLE_SIZE as needed.\n",
    "\n",
    "SAMPLE_SIZE = 50_000\n",
    "\n",
    "if len(df) > SAMPLE_SIZE:\n",
    "    df = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    print(f\"Sampled down to: {df.shape[0]} rows\")\n",
    "else:\n",
    "    print(f\"Dataset small enough ({df.shape[0]} rows), no sampling needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 9: Rename columns to standard FAQ format & reset index\n",
    "# ============================================================\n",
    "\n",
    "faq_df = df[['Question', 'Answer']].copy()\n",
    "faq_df.columns = ['question', 'answer']\n",
    "faq_df = faq_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final FAQ dataset shape: {faq_df.shape}\")\n",
    "print(f\"Nulls: {faq_df.isnull().sum().sum()}\")\n",
    "faq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ed52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 10: Save the final FAQ dataset\n",
    "# ============================================================\n",
    "\n",
    "faq_df.to_csv(\"dataset/faq_data.csv\", index=False)\n",
    "print(f\"Saved to dataset/faq_data.csv\")\n",
    "print(f\"Total FAQ pairs: {len(faq_df)}\")\n",
    "print(f\"\\nFile size: {pd.io.common.file_exists('dataset/faq_data.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 11: Quick sanity check — verify the saved file\n",
    "# ============================================================\n",
    "\n",
    "check = pd.read_csv(\"dataset/faq_data.csv\")\n",
    "print(f\"Loaded back: {check.shape}\")\n",
    "print(f\"Columns: {check.columns.tolist()}\")\n",
    "print(f\"\\nRandom samples:\")\n",
    "for i, row in check.sample(5, random_state=1).iterrows():\n",
    "    print(f\"\\n  Q: {row['question'][:80]}...\")\n",
    "    print(f\"  A: {row['answer'][:80]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
